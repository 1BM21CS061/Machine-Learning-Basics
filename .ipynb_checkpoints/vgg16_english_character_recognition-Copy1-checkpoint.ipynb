{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6dc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde66edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1200, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image               # to load images\n",
    "from IPython.display import display # to display images\n",
    "\n",
    "pil_im = Image.open(r\"C:\\Users\\G Sai Madhav\\Desktop\\robotics\\3RD SEM project\\datast\\Img\\img014-048.png\")\n",
    "image = np.array(pil_im)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8337f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [100,100]\n",
    "\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights=None, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10bbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbab4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(26, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27099e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4abf24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                119834    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,834,522\n",
      "Trainable params: 14,834,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47bc0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84382c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb01c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img011-001.png', 'img011-002.png', 'img011-003.png', 'img011-004.png', 'img011-005.png']\n",
      "1430\n"
     ]
    }
   ],
   "source": [
    "directory = r\"C:\\Users\\G Sai Madhav\\Desktop\\robotics\\3RD SEM project\\datast\\Img\"\n",
    "files=os.listdir(directory)\n",
    "print(files[0:5])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01037e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img011-001.png', 'img011-002.png', 'img011-003.png', 'img011-004.png', 'img011-005.png']\n",
      "1430\n"
     ]
    }
   ],
   "source": [
    "# filename and image data\n",
    "datafile=[]\n",
    "data=[]\n",
    "for file in files:\n",
    "    image=load_img(os.path.join(directory,file),grayscale=False,color_mode='rgb',target_size=(100,100))\n",
    "    image=img_to_array(image)\n",
    "    image=image/255.0\n",
    "    data+=[image]\n",
    "    datafile+=[file]\n",
    "print(datafile[0:5])\n",
    "print(len(datafile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dce6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee74c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Img/img011-001.png</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Img/img011-002.png</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Img/img011-003.png</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Img/img011-004.png</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Img/img011-005.png</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image label\n",
       "0  Img/img011-001.png     A\n",
       "1  Img/img011-002.png     A\n",
       "2  Img/img011-003.png     A\n",
       "3  Img/img011-004.png     A\n",
       "4  Img/img011-005.png     A"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engl=pd.read_csv(r\"C:\\Users\\G Sai Madhav\\Desktop\\robotics\\3RD SEM project\\datast\\english.csv\")\n",
    "engl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c236d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 25 25 25]\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
      "       'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "factlabel=pd.factorize(engl['label'])\n",
    "\n",
    "print(factlabel[0])\n",
    "print(factlabel[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff4c89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                image label            file  labeln\n",
      "0  Img/img011-001.png     A  img011-001.png       0\n",
      "1  Img/img011-002.png     A  img011-002.png       0\n",
      "2  Img/img011-003.png     A  img011-003.png       0\n",
      "3  Img/img011-004.png     A  img011-004.png       0\n",
      "4  Img/img011-005.png     A  img011-005.png       0\n"
     ]
    }
   ],
   "source": [
    "labelfile=[]\n",
    "for item in engl['image']:\n",
    "    labelfile+=[item[4:]]\n",
    "engl['file']=labelfile\n",
    "engl['labeln']=factlabel[0]\n",
    "\n",
    "print(engl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e140f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "['img012-046.png', 'img012-047.png', 'img012-048.png', 'img012-049.png', 'img012-050.png', 'img012-051.png', 'img012-052.png', 'img012-053.png', 'img012-054.png', 'img012-055.png']\n"
     ]
    }
   ],
   "source": [
    "engl2=[]\n",
    "for item in datafile:\n",
    "    #print([engl['labeln'][engl['file']==item]])\n",
    "    engl2+=[engl['labeln'][engl['file']==item].values[0]]\n",
    "    \n",
    "print(engl2[100:110])\n",
    "print(datafile[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a713835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:(1430, 100, 100, 3)\n",
      "Labels shape: (1430, 26)\n"
     ]
    }
   ],
   "source": [
    "labels1=to_categorical(engl2)\n",
    "labels2=np.array(labels1)\n",
    "\n",
    "print(\"Data Shape:{}\\nLabels shape: {}\".format(data1.shape,labels2.shape))\n",
    "xtr = data1\n",
    "xt = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7723e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx,testx,trainy,testy=train_test_split(data1,labels2,test_size=0.2,random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8c14730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 100, 100, 3)\n",
      "(1144, 26)\n",
      "(286, 100, 100, 3)\n",
      "(286, 26)\n",
      "(1430, 100, 100, 3)\n",
      "(1430, 26)\n"
     ]
    }
   ],
   "source": [
    "print(trainx.shape)\n",
    "print(trainy.shape)\n",
    "print(testx.shape)\n",
    "print(testy.shape)\n",
    "print(data1.shape)\n",
    "print(labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61550642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 135s 4s/step - loss: 3.3249 - accuracy: 0.0385\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 136s 4s/step - loss: 3.2582 - accuracy: 0.0358\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 134s 4s/step - loss: 3.2580 - accuracy: 0.0315\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 134s 4s/step - loss: 3.2580 - accuracy: 0.0428\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 135s 4s/step - loss: 3.2579 - accuracy: 0.0428\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 132s 4s/step - loss: 3.2578 - accuracy: 0.0428\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 130s 4s/step - loss: 3.2576 - accuracy: 0.0350\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 130s 4s/step - loss: 3.2575 - accuracy: 0.0428\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 132s 4s/step - loss: 3.2573 - accuracy: 0.0428\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 132s 4s/step - loss: 3.2575 - accuracy: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec98de0dc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainx, trainy, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42b43bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 12s 637ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e971d40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae285df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(testy[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d346bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 7s 638ms/step - loss: 3.2682 - accuracy: 0.0210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.268200159072876, 0.02097902074456215]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testx,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8db7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_character_recog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d132cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
